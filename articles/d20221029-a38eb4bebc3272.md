---
title: "デプロイの頻度を向上させることへの誤解"
emoji: "♻️"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["DevOps","Four Keys","deployment frequency", ""]
published: false
---

# デプロイ頻度(Deployment Frequency)とは

組織のパフォーマンス(収益性など)と、デリバリのパフォーマンスは高い相関があります。
デリバリのパフォーマンスとしては、Four Keysと呼ばれる4つの指標が有名です。

参考: [エリート DevOps チームであることを Four Keys プロジェクトで確認する](https://cloud.google.com/blog/ja/products/gcp/using-the-four-keys-to-measure-your-devops-performance?hl=ja)

そのうちの１つであるデプロイ頻度とは、文字通り本番環境にリリースされた頻度のことを指します。
2022年のState of DevOps Reportによると、例えばデプロイ頻度において、高パフォーマーと低パフォーマーには以下のような雲泥の差があることが記されています。

- high performerのデプロイ頻度はおよそ1日4回、1年間で1460回。
- low performerは1ヶ月に1回〜6ヶ月に1回の頻度でしかデプロイを行っておらず、1年間の平均デプロイ頻度は約3.4回。 
- この比を取ると417倍もの差。

一方で、デプロイ頻度を向上させることは無意味・リスキーと考えている方々も多いと思います。
この記事では、デプロイ頻度を向上させることに対する誤解を扱います。

#　デプロイ頻度を上げることへの誤解

## 多くのバグはデプロイに起因する。デプロイを頻繁に行うなんて頭がおかしい。

バグはデプロイがトリガーというのはその通りかもしれませんが、デプロイが原因というのは因果関係が誤っていると思われます。
バグは、ソースコードの変更が原因で起こるのであり、デプロイはそのトリガーになっているだけです。
交番数の多い地域では検挙件数が多い傾向にあるので、犯罪を少なくするためには交番数は少ない方が良い、と言っているようなものではないでしょうか(ちょっと違う？笑)。

LoCが1000行のやや大きな変更をしたとして、中にはリファクタリングが3件、機能的な追加が1件が混ざっていたとします。
その中の、リファクタリングと機能追加でそれぞれバグが1個ずつ、計2個のバグがあったとします。

![](/images/a9dc6ab95780d0/image1.png)

これを250行×4回のデプロイに分けたとします。
4回のデプロイのうち2回のデプロイでバグが発生することになりますが、結局は計2個のバグしか発生しません。
当たり前ですが、デプロイする変更総量が同じであれば、発生するバグの総量も原則として変わらないはずです。

![](/images/a9dc6ab95780d0/image1.png)

## デプロイ頻度を上げることを目指すと、ひたすらに小さいプルリクエストを作る輩が発生する。

もちろん、あまりにも無意味な分け方をしているというのであれば、あまり健全とは言えません。
しかし、意味のある単位でプルリクエストを小さく分割するのは様々な効果があり、むしろ歓迎されるべきことです。
例えば、小さいプルリクエストは、コードの変更量やレビュー側への負担も少なくなり、リードタイムが縮みます。

[LeanとDevOpsの科学](https://www.amazon.co.jp/dp/4295004901) でも、バッチサイズ(一度に進める作業のサイズ)の代わりに、デプロイ頻度を測定基準にすることに決めたと書いてあります。

> 第2の測定尺度はバッチサイズ(一度に進める作業のサイズ)である。
> (中略)
> バッチサイズの削減によって得られる効果は、サイクルタイムの短縮とフローにおける変動の低減、フィードバックの高速化、リスクと諸経費の軽減、効率、モチベーション、緊急性の認識の向上、コストとスケジュールの膨張の抑制である。
> ただ、ソフトウェアの場合は目に見える商品が存在しないため、バッチサイズを測定してその結果を伝えるということが難しい。
> そのため、我々は「バッチサイズ」の代わりに「デプロイの頻度」を測定基準とすることに決めた。
> デプロイ頻度のほうが測定が容易な上に、通常、変動も小さいからである。

## 本番環境の挙動が変わらないデプロイをしても、機能が追加されるわけではないから無駄である。

本番環境にはアプリケーションのログ、可用性やレイテンシ、サーバのCPU・ディスクの使用率など、あらゆる監視体制を整えているはずです。
挙動が変化しないデプロイであっても、デプロイ後にそれらのメトリクスが変化しなかったというフィードバックが返ってきます。
これらのフィードバックを得ることで、変更は結果として成功であったと分かります。
逆に関連するバグ・アラートが報告された場合には、変更は結果として失敗であったと分かります。

![](/images/a9dc6ab95780d0/image1.png)

挙動が変わらないデプロイであっても、結果として成功だったというフィードバックを得られるという、十分な価値があります。

## デプロイは大掛かりな作業なので、小さい変更量のデプロイは無駄である。

デプロイパイプラインに改善点があるということだと思います。
フィードバックループを回していくためにも、デプロイは頻繁に行うようにしたいので、デプロイの負荷は限りなく小さくしたいです。

[LeanとDevOpsの科学](https://www.amazon.co.jp/dp/4295004901) では、デプロイの負荷を軽減する措置として、以下を挙げています。

> ・複数の環境に容易にデプロイでき、その環境における不具合を検知・許容でき、システムの各種コンポーネントをそれぞれ独立した形で更新できるよう設計する
> ・本番システムの状態は、バージョンコントロールの情報に基づき、自動化された方法で再現できるようにする(ただし本番データは除く)
> ・アプリケーションとプラットフォームをより賢いものにし、デプロイプロセスを極力簡素化する

## バッチ実行中はデプロイが出来ないので、デプロイできる時間が決まっている。

これもデプロイパイプラインに改善点があるということだと思います。

参考: [NewsPicksにCTOとして入社して1年でDX Criteriaを大幅改善した話](https://tech.uzabase.com/entry/2021/01/28/190209)

## 動作確認・QAの回数が多くなり、大変になる。

逆だと考えています。
デプロイする変更量が少なければ、動作確認すべき項目も明確になり、QAのデバッグ時における問題の切り分けを進めやすいです。
回数は多くなるものの、一回あたりの時間は減少するはずです。

また、動作確認・QAの精度が向上するので、変更失敗率を下げる効果があります。
全体としては歓迎されるべきものと考えます。

デプロイ時に毎回確認・承認などを行う手作業・フローがヘッダとして乗っかってしまう、という事情も考えられます。
これの解決案としては、手作業・フローとなっているものをCIなどに組み込めないかを考えるのも手だと思っています。
例えばQAが毎回確認している項目があれば、それはCIのテスト項目として保証するようにする、などです。

## うちはBtoB。顧客のためにもサービスを止める危険は極力減らしたい。

BtoCでもサービスが停止することは収益の大幅な減少に繋がります。
致命の度合いに大小はあれど、サービスの停止が辛いのはBtoBに限った話ではありません。

また、前述の通りデプロイ頻度を増やすことは、リスクの軽減・緊急性の認識の向上という効果があります。
顧客のためにサービスを極力止めたくないのであれば、むしろデプロイ頻度は増やすべきです。
例えとして適切でないかもしれませんが、自転車は走り続けた方が安定して走行できます。

## サービス利用の多い日中 or 取引先の業務中にサービスを止めたくないのでデプロイはできない。リリース日やリリース時間が決まっている。

むしろ、日中や取引先の業務中にデプロイした方が良いです。

実際のデータと、開発上で想定していたデータが異なるというのはよくある話です。
また、監視体制は本番環境に集中させる傾向があります。
これらから、本番環境にデプロイし、実際にサービスを使用させないと(現実的なコストを払う範囲では)気付けないバグというものが、どうしても一定存在します。

例えば、サービス利用の多い日中のデプロイを避けると、以下のような問題が起きます。
- 利用者が少なく、アラートも少ないなどの理由で気付けない
- あるいはオンコール担当者がアラートに気付けても、対応できる実装者が不在のため原因が不明 or 復旧できない

よって、サービス利用の多い日中のデプロイを避けると、結果的にバグ発生の時間が長くなりがちになります。

![](/images/a9dc6ab95780d0/image1.png)

普通に日中にデプロイしていれば、アラートにも気づきやすく、対応できる実装者も残っている可能性が高くなり、バグ発生の時間が短くなります。

![](/images/a9dc6ab95780d0/image1.png)

取引先の業務中を避けたいとするケースでも、同じ問題が起きます。
すなわち、利用者が少なく、アラートも少ないなどの理由で気付けないことがあります。
また、デプロイ時間をズラしたとしても結局はバグっています。
取引先が業務開始したときにはバグが継続しており、怒られが発生するのには変わりません。
厳しい言い方をすると、デプロイ時間をずらすのはただの問題の先延ばしであり、問題をより深刻化させるだけと考えます。

![](/images/a9dc6ab95780d0/image1.png)
![](/images/a9dc6ab95780d0/image1.png)

また、一度デプロイしてしまうと、前の状態に戻すのが難しく(あるいは不可能な)、どのくらいのバグ発生の時間の長さになってしまうかを取引先に説明できない、と心配する方もいると思います。
これはデプロイ後にロールバックできる仕組みをちゃんと整えておくべしという話になります。
前述の、「本番システムの状態は、バージョンコントロールの情報に基づき、自動化された方法で再現できるようにする」という設計にしておけば、この心配は軽減されるかと思います。

まあここは、法令や業界によってはどうしてもリリースできない時間帯があるケースが存在するというのは認めます。
あとは、業務開始時に障害が起きるのと比べ、業務時間中で突然障害が起きてしまうと心証的によりマイナスになりやすいとか(これらは取引先と交渉する人も、ある程度は頑張って欲しい)。

## マージは頻繁に行っている。それを週1回のデプロイでリリースしているだけだ。結局はリリースする変更量は同じだ。

本番環境へのデプロイでないと、顧客や監視体制からのフィードバックが返ってきません。
本番環境にデプロイすることが大切です。
また、まとめてリリースすると、バグ発生時に原因の切り分けが難しいため、復旧までの時間が長くなってしまいがちです。
マージとデプロイはなるべく密結合にするのが良いと思っています。

## Git Flowで運用しているし、developへのマージの頻度で良いよね？

本番へのリリースでないと、顧客や監視体制からのフィードバックが返ってきません(2回目)。
ちなみに [LeanとDevOpsの科学](https://www.amazon.co.jp/dp/4295004901) でも、トランクベースの開発により、デリバリパフォーマンスが向上すると書いてあります。
Git Flow自体を見直してみるのも手だと思います。

参考: [DevOps 技術: トランクベース開発](https://cloud.google.com/architecture/devops/devops-tech-trunk-based-development?hl=ja)

# まとめ

デプロイ頻度を上げることに対する、よくある誤解を扱ってみました。
「うちは事情が違う」と思いたくなるのは理解できますが、一度は「高デプロイ頻度があるべき姿である、それが実現できない原因を取り除こう」という思考をしてみて欲しいと思ってます。
LeanとDevOpsの科学の宣伝記事みたいになってもうたです。
コメント・マサカリなどお待ちしてます。